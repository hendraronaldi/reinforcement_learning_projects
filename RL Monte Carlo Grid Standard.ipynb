{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RL Monte Carlo Grid Standard.ipynb","provenance":[{"file_id":"1XqgnGN7Cc9LSq3jFXgAo2FPFUT9_oFuY","timestamp":1597990924821}],"collapsed_sections":[],"authorship_tag":"ABX9TyNqO5R9uGLkXtOiTrj7nvZh"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wqk9u4Y6c1ju","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598015320692,"user_tz":-420,"elapsed":717,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"ae5y3AdmK4eB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598015320972,"user_tz":-420,"elapsed":994,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["ACTION_SPACE = ('U', 'D', 'L', 'R')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"4y21_Xvpc-MI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598015321451,"user_tz":-420,"elapsed":1471,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["class Grid:\n","    def __init__(self, rows, columns, start):\n","        self.rows = rows\n","        self.columns = columns\n","        self.i = start[0]\n","        self.j = start[1]\n","\n","    def set_rewards_actions(self, rewards, actions):\n","        self.rewards = rewards\n","        self.actions = actions\n","    \n","    def get_state(self):\n","        return (self.i, self.j)\n","\n","    def set_state(self, s):\n","        self.i = s[0]\n","        self.j = s[1]\n","\n","    def get_next_state(self, s, a):\n","        i, j = s[0], s[1]\n","        if a in self.actions[(i, j)]:\n","            if a == 'U':\n","                i -= 1\n","            elif a == 'D':\n","                i += 1\n","            elif a == 'L':\n","                j -= 1\n","            elif a == 'R':\n","                j += 1\n","        return i, j\n","    \n","    def move(self, a):\n","        if a in self.actions[(self.i, self.j)]:\n","            if a == 'U':\n","                self.i -= 1\n","            elif a == 'D':\n","                self.i += 1\n","            elif a == 'L':\n","                self.j -= 1\n","            elif a == 'R':\n","                self.j += 1\n","        return self.rewards.get((self.i, self.j), 0)\n","    \n","    def undo_move(self, a):\n","        if a == 'U':\n","            self.i += 1\n","        elif a == 'D':\n","            self.i -= 1\n","        elif a == 'L':\n","            self.j += 1\n","        elif a == 'R':\n","            self.j -= 1\n","        assert (self.get_state() in self.all_states())\n","    \n","    def is_terminal(self, s):\n","        return s not in self.actions\n","\n","    def game_over(self):\n","        return (self.i, self.j) not in self.actions\n","\n","    def all_states(self):\n","        return set(self.actions.keys() | self.rewards.keys())"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"LsLDOoqVdlmM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598015321451,"user_tz":-420,"elapsed":1470,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def grid_standard():\n","    g = Grid(3, 4, (2, 0))\n","    rewards = {\n","        (0,3): 1,\n","        (1,3): -1\n","    }\n","    \n","    actions = {\n","        (0, 0): ('D', 'R'),\n","        (0, 1): ('L', 'R'),\n","        (0, 2): ('L', 'D', 'R'),\n","        (1, 0): ('U', 'D'),\n","        (1, 2): ('U', 'D', 'R'),\n","        (2, 0): ('U', 'R'),\n","        (2, 1): ('L', 'R'),\n","        (2, 2): ('U', 'L', 'R'),\n","        (2, 3): ('U', 'L')\n","    }\n","\n","    g.set_rewards_actions(rewards, actions)\n","\n","    return g"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3drjW76Letjh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598015321452,"user_tz":-420,"elapsed":1467,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def print_values(V, g):\n","    for i in range(g.rows):\n","        print(\"-------------------------\")\n","        for j in range(g.columns):\n","            v = V.get((i, j), 0)\n","            if v >= 0:\n","                print(\" %.2f|\" % v, end=\"\")\n","            else:\n","                print(\"%.2f|\" % v, end=\"\")\n","        print(\"\")\n","\n","def print_policy(P, g):\n","    for i in range(g.rows):\n","        print(\"-------------------------\")\n","        for j in range(g.columns):\n","            a = P.get((i, j), ' ')\n","            print(\" %s |\" % a, end=\"\")\n","        print(\"\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"EptCSbcFNNWT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598015321453,"user_tz":-420,"elapsed":1466,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def t_probs_rewards(g):\n","    transition_probs = {}\n","\n","    rewards = {}\n","\n","    for i in range(g.rows):\n","        for j in range(g.columns):\n","            s = (i, j)\n","            if not g.is_terminal(s):\n","                for a in ACTION_SPACE:\n","                    s_next = g.get_next_state(s, a)\n","                    transition_probs[(s, a, s_next)] = 1 # prob of s with action to reach s_next is 1 because deterministic\n","                    if s_next in g.rewards:\n","                        rewards[(s, a, s_next)] = g.rewards[s_next]\n","    return transition_probs, rewards"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvHbZzYcQ2he","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598015321453,"user_tz":-420,"elapsed":1464,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def evaluate_deterministic_policy(g, policy):\n","    V = {}\n","    for s in g.all_states():\n","        V[s] = 0\n","    iterations = 0\n","\n","    while True:\n","        biggest_change = 0\n","        for s in g.all_states():\n","            old_v = V[s]\n","            new_v = 0\n","            for a in ACTION_SPACE:\n","                for s_next in g.all_states():\n","                    action_prob = 1 if policy.get(s) == a else 0\n","\n","                    r = rewards.get((s, a, s_next), 0)\n","\n","                    new_v += action_prob * transition_probs.get((s, a, s_next), 0) * (r + gamma * V[s_next])\n","\n","            V[s] = new_v\n","            biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n","\n","        iterations += 1\n","        if biggest_change < delta:\n","            break\n","\n","    return V"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"PIT9v4o4tDgN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598015321454,"user_tz":-420,"elapsed":1462,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def get_optimal_policy(g, policy):\n","    while True:\n","        V = evaluate_deterministic_policy(g, policy)\n","\n","        is_policy_converged = True\n","        for s in g.actions.keys():\n","            old_a = policy[s]\n","            new_a = None\n","            best_value = float('-inf')\n","\n","            for a in ACTION_SPACE:\n","                v = 0\n","                for s_next in g.all_states():\n","                    r = rewards.get((s, a, s_next), 0)\n","                    v += transition_probs.get((s, a, s_next), 0) * (r + gamma * V[s_next])\n","\n","                if v > best_value:\n","                    best_value = v\n","                    new_a = a\n","            \n","            policy[s] = new_a\n","\n","            if new_a != old_a:\n","                is_policy_converged = False\n","            \n","        if is_policy_converged:\n","            break\n","    return V, policy"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEMsuj_PrAc4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1598018341579,"user_tz":-420,"elapsed":2560,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}},"outputId":"40ffa7cf-9547-4061-9b4b-732ebce4ad01"},"source":["# initialize variable\n","g = grid_standard()\n","delta = 1e-4\n","gamma = 0.9\n","\n","# random policy\n","policy = {}\n","for s in g.actions.keys():\n","    policy[s] = np.random.choice(ACTION_SPACE)\n","\n","print(\"initial policy\")\n","print_policy(policy, g)\n","print(\"\")\n","\n","transition_probs, rewards = t_probs_rewards(g)\n","\n","V, policy = get_optimal_policy(g, policy)\n","print(\"optimal policy\")\n","print_policy(policy, g)\n","print(\"V\")\n","print_values(V, g)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["initial policy\n","-------------------------\n"," D | L | U |   |\n","-------------------------\n"," R |   | R |   |\n","-------------------------\n"," L | L | R | R |\n","\n","optimal policy\n","-------------------------\n"," R | R | R |   |\n","-------------------------\n"," U |   | U |   |\n","-------------------------\n"," U | R | U | L |\n","V\n","-------------------------\n"," 0.81| 0.90| 1.00| 0.00|\n","-------------------------\n"," 0.73| 0.00| 0.90| 0.00|\n","-------------------------\n"," 0.66| 0.73| 0.81| 0.73|\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_jqkLUxSDFxr","colab_type":"text"},"source":["## Monte Carlo"]},{"cell_type":"code","metadata":{"id":"mwvaMqmbsnWr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598018341580,"user_tz":-420,"elapsed":2550,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def play_game(g, policy):\n","    start_states = list(g.actions.keys())\n","    start_idx = np.random.choice(len(start_states))\n","    g.set_state(start_states[start_idx])\n","\n","    s = g.get_state()\n","    states_and_rewards = [(s, 0)] # at the start reward = 0\n","\n","    while not g.game_over(): # update (s, r) for every state visited based on policy\n","        a = policy[s]\n","        r = g.move(a)\n","        s = g.get_state()\n","        states_and_rewards.append((s, r))\n","\n","    G = 0\n","    states_and_returns = []\n","    first = True\n","\n","    for s, r in reversed(states_and_rewards): # backwards iteration from terminal state\n","        if first:\n","            first = False\n","        else:\n","            states_and_returns.append((s, G))\n","        \n","        G = r + gamma * G\n","    states_and_returns.reverse()\n","    return states_and_returns"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mr9vlv3RJwSc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598018341583,"user_tz":-420,"elapsed":2549,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def monte_carlo(g, policy, V, returns, episodes):\n","    for t in range(episodes):\n","        states_and_returns = play_game(g, policy)\n","        seen_states = set()\n","\n","        for s, G in states_and_returns:\n","            if s not in seen_states:\n","                returns[s].append(G)\n","                V[s] = np.mean(returns[s])\n","                seen_states.add(s)\n","    \n","    return V, policy"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"kw5B_y0SIop3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"ok","timestamp":1598018341584,"user_tz":-420,"elapsed":2545,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}},"outputId":"e768708c-69fd-4c94-9787-3ff006a0a896"},"source":["g = grid_standard()\n","\n","print(\"rewards:\")\n","print_values(g.rewards, g)\n","\n","policy = {\n","    (2, 0): 'U',\n","    (1, 0): 'U',\n","    (0, 0): 'R',\n","    (0, 1): 'R',\n","    (0, 2): 'R',\n","    (1, 2): 'R',\n","    (2, 1): 'R',\n","    (2, 2): 'R',\n","    (2, 3): 'U',\n","}\n","\n","V = {}\n","returns = {}\n","\n","for s in g.all_states():\n","    if s in g.actions:\n","        returns[s] = []\n","    else:\n","        V[s] = 0\n","\n","V, policy = monte_carlo(g, policy, V, returns, 100)\n","\n","print(\"values\")\n","print_values(V, g)\n","print(\"policy\")\n","print_policy(policy, g)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["rewards:\n","-------------------------\n"," 0.00| 0.00| 0.00| 1.00|\n","-------------------------\n"," 0.00| 0.00| 0.00|-1.00|\n","-------------------------\n"," 0.00| 0.00| 0.00| 0.00|\n","values\n","-------------------------\n"," 0.81| 0.90| 1.00| 0.00|\n","-------------------------\n"," 0.73| 0.00|-1.00| 0.00|\n","-------------------------\n"," 0.66|-0.81|-0.90|-1.00|\n","policy\n","-------------------------\n"," R | R | R |   |\n","-------------------------\n"," U |   | R |   |\n","-------------------------\n"," U | R | R | U |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"adIWBQFhWvTh","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}