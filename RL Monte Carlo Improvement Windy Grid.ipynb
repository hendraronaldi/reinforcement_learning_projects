{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RL Monte Carlo Improvement Windy Grid.ipynb","provenance":[{"file_id":"1efUSUaigrW0bcmAyqhMVmhl9XgPtNsEE","timestamp":1598019028250},{"file_id":"1XqgnGN7Cc9LSq3jFXgAo2FPFUT9_oFuY","timestamp":1597990924821}],"collapsed_sections":[],"authorship_tag":"ABX9TyOngdiI+7R3jn6X5+BMnEWb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wqk9u4Y6c1ju","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102821820,"user_tz":-420,"elapsed":1345,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"ae5y3AdmK4eB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102821821,"user_tz":-420,"elapsed":1339,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["ACTION_SPACE = ('U', 'D', 'L', 'R')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"4y21_Xvpc-MI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822569,"user_tz":-420,"elapsed":2082,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["class Grid:\n","    def __init__(self, rows, columns, start):\n","        self.rows = rows\n","        self.columns = columns\n","        self.i = start[0]\n","        self.j = start[1]\n","\n","    def set_rewards_actions(self, rewards, actions):\n","        self.rewards = rewards\n","        self.actions = actions\n","    \n","    def get_state(self):\n","        return (self.i, self.j)\n","\n","    def set_state(self, s):\n","        self.i = s[0]\n","        self.j = s[1]\n","\n","    def get_next_state(self, s, a):\n","        i, j = s[0], s[1]\n","        if a in self.actions[(i, j)]:\n","            if a == 'U':\n","                i -= 1\n","            elif a == 'D':\n","                i += 1\n","            elif a == 'L':\n","                j -= 1\n","            elif a == 'R':\n","                j += 1\n","        return i, j\n","    \n","    def move(self, a):\n","        if a in self.actions[(self.i, self.j)]:\n","            if a == 'U':\n","                self.i -= 1\n","            elif a == 'D':\n","                self.i += 1\n","            elif a == 'L':\n","                self.j -= 1\n","            elif a == 'R':\n","                self.j += 1\n","        return self.rewards.get((self.i, self.j), 0)\n","    \n","    def undo_move(self, a):\n","        if a == 'U':\n","            self.i += 1\n","        elif a == 'D':\n","            self.i -= 1\n","        elif a == 'L':\n","            self.j += 1\n","        elif a == 'R':\n","            self.j -= 1\n","        assert (self.get_state() in self.all_states())\n","    \n","    def is_terminal(self, s):\n","        return s not in self.actions\n","\n","    def game_over(self):\n","        return (self.i, self.j) not in self.actions\n","\n","    def all_states(self):\n","        return set(self.actions.keys() | self.rewards.keys())"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"LsLDOoqVdlmM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822570,"user_tz":-420,"elapsed":2078,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def grid_standard():\n","    g = Grid(3, 4, (2, 0))\n","    rewards = {\n","        (0,3): 1,\n","        (1,3): -1\n","    }\n","    \n","    actions = {\n","        (0, 0): ('D', 'R'),\n","        (0, 1): ('L', 'R'),\n","        (0, 2): ('L', 'D', 'R'),\n","        (1, 0): ('U', 'D'),\n","        (1, 2): ('U', 'D', 'R'),\n","        (2, 0): ('U', 'R'),\n","        (2, 1): ('L', 'R'),\n","        (2, 2): ('U', 'L', 'R'),\n","        (2, 3): ('U', 'L')\n","    }\n","\n","    g.set_rewards_actions(rewards, actions)\n","\n","    return g"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3drjW76Letjh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822571,"user_tz":-420,"elapsed":2074,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def print_values(V, g):\n","    for i in range(g.rows):\n","        print(\"-------------------------\")\n","        for j in range(g.columns):\n","            v = V.get((i, j), 0)\n","            if v >= 0:\n","                print(\" %.2f|\" % v, end=\"\")\n","            else:\n","                print(\"%.2f|\" % v, end=\"\")\n","        print(\"\")\n","\n","def print_policy(P, g):\n","    for i in range(g.rows):\n","        print(\"-------------------------\")\n","        for j in range(g.columns):\n","            a = P.get((i, j), ' ')\n","            print(\" %s |\" % a, end=\"\")\n","        print(\"\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"EptCSbcFNNWT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822572,"user_tz":-420,"elapsed":2070,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def t_probs_rewards(g):\n","    transition_probs = {}\n","\n","    rewards = {}\n","\n","    for i in range(g.rows):\n","        for j in range(g.columns):\n","            s = (i, j)\n","            if not g.is_terminal(s):\n","                for a in ACTION_SPACE:\n","                    s_next = g.get_next_state(s, a)\n","                    transition_probs[(s, a, s_next)] = 1 # prob of s with action to reach s_next is 1 because deterministic\n","                    if s_next in g.rewards:\n","                        rewards[(s, a, s_next)] = g.rewards[s_next]\n","    return transition_probs, rewards"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvHbZzYcQ2he","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822572,"user_tz":-420,"elapsed":2065,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def evaluate_deterministic_policy(g, policy):\n","    V = {}\n","    for s in g.all_states():\n","        V[s] = 0\n","    iterations = 0\n","\n","    while True:\n","        biggest_change = 0\n","        for s in g.all_states():\n","            old_v = V[s]\n","            new_v = 0\n","            for a in ACTION_SPACE:\n","                for s_next in g.all_states():\n","                    action_prob = 1 if policy.get(s) == a else 0\n","\n","                    r = rewards.get((s, a, s_next), 0)\n","\n","                    new_v += action_prob * transition_probs.get((s, a, s_next), 0) * (r + gamma * V[s_next])\n","\n","            V[s] = new_v\n","            biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n","\n","        iterations += 1\n","        if biggest_change < delta:\n","            break\n","\n","    return V"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"PIT9v4o4tDgN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822573,"user_tz":-420,"elapsed":2061,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def get_optimal_policy(g, policy):\n","    while True:\n","        V = evaluate_deterministic_policy(g, policy)\n","\n","        is_policy_converged = True\n","        for s in g.actions.keys():\n","            old_a = policy[s]\n","            new_a = None\n","            best_value = float('-inf')\n","\n","            for a in ACTION_SPACE:\n","                v = 0\n","                for s_next in g.all_states():\n","                    r = rewards.get((s, a, s_next), 0)\n","                    v += transition_probs.get((s, a, s_next), 0) * (r + gamma * V[s_next])\n","\n","                if v > best_value:\n","                    best_value = v\n","                    new_a = a\n","            \n","            policy[s] = new_a\n","\n","            if new_a != old_a:\n","                is_policy_converged = False\n","            \n","        if is_policy_converged:\n","            break\n","    return V, policy"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEMsuj_PrAc4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1598102822574,"user_tz":-420,"elapsed":2053,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}},"outputId":"b270495f-b7b6-4c5f-89c4-89ed8bd5b97c"},"source":["# initialize variable\n","g = grid_standard()\n","delta = 1e-4\n","gamma = 0.9\n","\n","# random policy\n","policy = {}\n","for s in g.actions.keys():\n","    policy[s] = np.random.choice(ACTION_SPACE)\n","\n","print(\"initial policy\")\n","print_policy(policy, g)\n","print(\"\")\n","\n","transition_probs, rewards = t_probs_rewards(g)\n","\n","V, policy = get_optimal_policy(g, policy)\n","print(\"optimal policy\")\n","print_policy(policy, g)\n","print(\"V\")\n","print_values(V, g)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["initial policy\n","-------------------------\n"," D | L | R |   |\n","-------------------------\n"," D |   | D |   |\n","-------------------------\n"," U | L | R | L |\n","\n","optimal policy\n","-------------------------\n"," R | R | R |   |\n","-------------------------\n"," U |   | U |   |\n","-------------------------\n"," U | R | U | L |\n","V\n","-------------------------\n"," 0.81| 0.90| 1.00| 0.00|\n","-------------------------\n"," 0.73| 0.00| 0.90| 0.00|\n","-------------------------\n"," 0.66| 0.73| 0.81| 0.73|\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_jqkLUxSDFxr","colab_type":"text"},"source":["## Monte Carlo"]},{"cell_type":"code","metadata":{"id":"2t9bjtUjXAD7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822575,"user_tz":-420,"elapsed":2048,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def random_action(a):\n","    p = np.random.random()\n","    if p < 0.5:\n","        return a\n","    else:\n","        tmp = list(ACTION_SPACE)\n","        tmp.remove(a)\n","        return np.random.choice(tmp)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"mwvaMqmbsnWr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822575,"user_tz":-420,"elapsed":2043,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def play_game(g, policy):\n","    start_states = list(g.actions.keys())\n","    start_idx = np.random.choice(len(start_states))\n","    g.set_state(start_states[start_idx])\n","\n","    s = g.get_state()\n","    states_and_rewards = [(s, 0)] # at the start reward = 0\n","\n","    while not g.game_over(): # update (s, r) for every state visited based on policy\n","        a = policy[s]\n","        a = random_action(a)\n","        r = g.move(a)\n","        s = g.get_state()\n","        states_and_rewards.append((s, r))\n","\n","    G = 0\n","    states_and_returns = []\n","    first = True\n","\n","    for s, r in reversed(states_and_rewards): # backwards iteration from terminal state\n","        if first:\n","            first = False\n","        else:\n","            states_and_returns.append((s, G))\n","        \n","        G = r + gamma * G\n","    states_and_returns.reverse()\n","    return states_and_returns"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OItw2sCBTao","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102821817,"user_tz":-420,"elapsed":1351,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def play_game_random_start_action(g, policy):\n","    start_states = list(g.actions.keys())\n","    start_idx = np.random.choice(len(start_states))\n","    g.set_state(start_states[start_idx])\n","\n","    s = g.get_state()\n","    a = np.random.choice(ACTION_SPACE) # random actions at start\n","\n","    states_actions_rewards = [(s, a, 0)]\n","    seen_states = set() # record visited states\n","    seen_states.add(s)\n","    n_steps = 0\n","\n","    while True:\n","        r = g.move(a)\n","        s = g.get_state()\n","        n_steps += 1\n","\n","        if s in seen_states: # prevent infinite looping in several states because using standard grid\n","            r = -10. / n_steps\n","            states_actions_rewards.append((s, None, r))\n","            break\n","        elif g.game_over():\n","            states_actions_rewards.append((s, None, r))\n","            break\n","        else:\n","            a = policy[s]\n","            states_actions_rewards.append((s, a, r))\n","        seen_states.add(s)\n","\n","    G = 0\n","    states_actions_returns = []\n","    first = True\n","\n","    for s, a, r in reversed(states_actions_rewards): # backwards iteration from terminal state\n","        if first:\n","            first = False\n","        else:\n","            states_actions_returns.append((s, a, G))\n","        \n","        G = r + gamma * G\n","    states_actions_returns.reverse()\n","    return states_actions_returns"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7SoDMsMCxGs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822576,"user_tz":-420,"elapsed":2040,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def max_dict(d):\n","    max_key = None\n","    max_val = float('-inf')\n","    for k, v in d.items():\n","        if v > max_val:\n","            max_val = v\n","            max_key = k\n","    return max_key, max_val"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IWnCf3i28xTz","colab_type":"text"},"source":["### Monte Carlo Evaluation"]},{"cell_type":"code","metadata":{"id":"Mr9vlv3RJwSc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822576,"user_tz":-420,"elapsed":2035,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def monte_carlo(g, policy, V, returns, num_of_iter):\n","    for t in range(num_of_iter):\n","        states_and_returns = play_game(g, policy)\n","        seen_states = set()\n","\n","        for s, G in states_and_returns:\n","            if s not in seen_states:\n","                returns[s].append(G)\n","                V[s] = np.mean(returns[s])\n","                seen_states.add(s)\n","    \n","    return V, policy"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PMuGBHZd80_g","colab_type":"text"},"source":["### Monte Carlo Improvement"]},{"cell_type":"code","metadata":{"id":"GlqRslkS833v","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598102822577,"user_tz":-420,"elapsed":2031,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def monte_carlo_improvement(g, policy, Q, returns, deltas, num_of_iter):\n","    for t in range(num_of_iter):\n","        if t % 1000 == 0:\n","            print(t)\n","\n","        states_actions_returns = play_game_random_start_action(g, policy)\n","        seen_states_actions = set()\n","\n","        biggest_change = 0\n","        for s, a, G in states_actions_returns:\n","            sa = (s, a)\n","            if sa not in seen_states_actions:\n","                old_Q = Q[s][a]\n","                returns[sa].append(G)\n","                Q[s][a] = np.mean(returns[sa])\n","                biggest_change = max(biggest_change, np.abs(old_Q - Q[s][a]))\n","                seen_states_actions.add(sa)\n","\n","        deltas.append(biggest_change)\n","\n","        for s in policy.keys():\n","            policy[s] = max_dict(Q[s])[0]\n","    \n","    return Q, policy, deltas"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EV8beiipETYU","colab_type":"text"},"source":["### Run Monte Carlo"]},{"cell_type":"code","metadata":{"id":"kw5B_y0SIop3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"ok","timestamp":1598102825001,"user_tz":-420,"elapsed":4446,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}},"outputId":"b06f43fd-abf6-4e9c-814e-cd261578b58a"},"source":["g = grid_standard()\n","\n","print(\"rewards:\")\n","print_values(g.rewards, g)\n","\n","policy = {\n","    (2, 0): 'U',\n","    (1, 0): 'U',\n","    (0, 0): 'R',\n","    (0, 1): 'R',\n","    (0, 2): 'R',\n","    (1, 2): 'U',\n","    (2, 1): 'L',\n","    (2, 2): 'U',\n","    (2, 3): 'L',\n","}\n","\n","V = {}\n","returns = {}\n","\n","for s in g.all_states():\n","    if s in g.actions:\n","        returns[s] = []\n","    else:\n","        V[s] = 0\n","\n","V, policy = monte_carlo(g, policy, V, returns, 5000)\n","\n","print(\"values\")\n","print_values(V, g)\n","print(\"policy\")\n","print_policy(policy, g)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["rewards:\n","-------------------------\n"," 0.00| 0.00| 0.00| 1.00|\n","-------------------------\n"," 0.00| 0.00| 0.00|-1.00|\n","-------------------------\n"," 0.00| 0.00| 0.00| 0.00|\n","values\n","-------------------------\n"," 0.44| 0.55| 0.72| 0.00|\n","-------------------------\n"," 0.34| 0.00| 0.20| 0.00|\n","-------------------------\n"," 0.26| 0.19| 0.10|-0.19|\n","policy\n","-------------------------\n"," R | R | R |   |\n","-------------------------\n"," U |   | U |   |\n","-------------------------\n"," U | L | U | L |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"adIWBQFhWvTh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":511},"executionInfo":{"status":"error","timestamp":1598102855205,"user_tz":-420,"elapsed":34642,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}},"outputId":"b11d5ff4-90fe-4c06-a487-9795a8f800ad"},"source":["g = grid_standard()\n","\n","print(\"rewards:\")\n","print_values(g.rewards, g)\n","\n","policy = {}\n","for s in list(g.actions.keys()):\n","    policy[s] = np.random.choice(ACTION_SPACE)\n","\n","Q = {}\n","returns = {}\n","for s in g.all_states():\n","    if s in g.actions:\n","        Q[s] = {}\n","        for a in ACTION_SPACE:\n","            Q[s][a] = 0\n","            returns[(s,a)] = []\n","\n","\n","deltas = []\n","\n","Q, policy, deltas = monte_carlo_improvement(g, policy, Q, returns, deltas, 5000)\n","\n","plt.figure(figsize=(16,8))\n","plt.plot(deltas)\n","plt.show()\n","\n","V = {}\n","for s, Qs in Q.items():\n","    V[s] = max_dict(Q[s])[1]\n","print(\"final values\")\n","print_values(V, g)\n","\n","\n","print(\"optimal policy\")\n","print_policy(policy, g)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["rewards:\n","-------------------------\n"," 0.00| 0.00| 0.00| 1.00|\n","-------------------------\n"," 0.00| 0.00| 0.00|-1.00|\n","-------------------------\n"," 0.00| 0.00| 0.00| 0.00|\n","0\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-c60c385404cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonte_carlo_improvement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-d9ec55b6b263>\u001b[0m in \u001b[0;36mmonte_carlo_improvement\u001b[0;34m(g, policy, Q, returns, deltas, num_of_iter)\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mstates_actions_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game_random_start_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mseen_states_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-602307d9a1ec>\u001b[0m in \u001b[0;36mplay_game_random_start_action\u001b[0;34m(g, policy)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mold_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mn_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-88db2f46d50f>\u001b[0m in \u001b[0;36mmove\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mundo_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"RPAeMJo3LYvH","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1598102855203,"user_tz":-420,"elapsed":34637,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":[""],"execution_count":null,"outputs":[]}]}