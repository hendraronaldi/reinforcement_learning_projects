{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RL Optimal Policy Gridworld Deterministic.ipynb","provenance":[{"file_id":"1XqgnGN7Cc9LSq3jFXgAo2FPFUT9_oFuY","timestamp":1597990924821}],"collapsed_sections":[],"authorship_tag":"ABX9TyN9opnEfSDsIwzMlHX8v/oN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wqk9u4Y6c1ju","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597991171424,"user_tz":-420,"elapsed":1209,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ae5y3AdmK4eB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597991172062,"user_tz":-420,"elapsed":1842,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["ACTION_SPACE = ('U', 'D', 'L', 'R')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"4y21_Xvpc-MI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597991172063,"user_tz":-420,"elapsed":1840,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["class Grid:\n","    def __init__(self, rows, columns, start):\n","        self.rows = rows\n","        self.columns = columns\n","        self.i = start[0]\n","        self.j = start[1]\n","\n","    def set_rewards_actions(self, rewards, actions):\n","        self.rewards = rewards\n","        self.actions = actions\n","    \n","    def get_state(self):\n","        return (self.i, self.j)\n","\n","    def set_state(self, s):\n","        self.i = s[0]\n","        self.j = s[1]\n","\n","    def get_next_state(self, s, a):\n","        i, j = s[0], s[1]\n","        if a in self.actions[(i, j)]:\n","            if a == 'U':\n","                i -= 1\n","            elif a == 'D':\n","                i += 1\n","            elif a == 'L':\n","                j -= 1\n","            elif a == 'R':\n","                j += 1\n","        return i, j\n","    \n","    def move(self, a):\n","        if a in self.actions[(self.i, self.j)]:\n","            if a == 'U':\n","                self.i -= 1\n","            elif a == 'D':\n","                self.i += 1\n","            elif a == 'L':\n","                self.j -= 1\n","            elif a == 'R':\n","                self.j += 1\n","        return self.rewards.get((self.i, self.j), 0)\n","    \n","    def undo_move(self, a):\n","        if a == 'U':\n","            self.i += 1\n","        elif a == 'D':\n","            self.i -= 1\n","        elif a == 'L':\n","            self.j += 1\n","        elif a == 'R':\n","            self.j -= 1\n","        assert (self.get_state() in self.all_states())\n","    \n","    def is_terminal(self, s):\n","        return s not in self.actions\n","\n","    def game_over(self):\n","        return (self.i, self.j) not in self.actions\n","\n","    def all_states(self):\n","        return set(self.actions.keys() | self.rewards.keys())"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"LsLDOoqVdlmM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597991172063,"user_tz":-420,"elapsed":1838,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def grid_standard():\n","    g = Grid(3, 4, (2, 0))\n","    rewards = {\n","        (0,3): 1,\n","        (1,3): -1\n","    }\n","    \n","    actions = {\n","        (0, 0): ('D', 'R'),\n","        (0, 1): ('L', 'R'),\n","        (0, 2): ('L', 'D', 'R'),\n","        (1, 0): ('U', 'D'),\n","        (1, 2): ('U', 'D', 'R'),\n","        (2, 0): ('U', 'R'),\n","        (2, 1): ('L', 'R'),\n","        (2, 2): ('U', 'L', 'R'),\n","        (2, 3): ('U', 'L')\n","    }\n","\n","    g.set_rewards_actions(rewards, actions)\n","\n","    return g"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3drjW76Letjh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597991172064,"user_tz":-420,"elapsed":1836,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def print_values(V, g):\n","    for i in range(g.rows):\n","        print(\"-------------------------\")\n","        for j in range(g.columns):\n","            v = V.get((i, j), 0)\n","            if v >= 0:\n","                print(\" %.2f|\" % v, end=\"\")\n","            else:\n","                print(\"%.2f|\" % v, end=\"\")\n","        print(\"\")\n","\n","def print_policy(P, g):\n","    for i in range(g.rows):\n","        print(\"-------------------------\")\n","        for j in range(g.columns):\n","            a = P.get((i, j), ' ')\n","            print(\" %s |\" % a, end=\"\")\n","        print(\"\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"EptCSbcFNNWT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597991172065,"user_tz":-420,"elapsed":1835,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def t_probs_rewards(g):\n","    transition_probs = {}\n","\n","    rewards = {}\n","\n","    for i in range(g.rows):\n","        for j in range(g.columns):\n","            s = (i, j)\n","            if not g.is_terminal(s):\n","                for a in ACTION_SPACE:\n","                    s_next = g.get_next_state(s, a)\n","                    transition_probs[(s, a, s_next)] = 1 # prob of s with action to reach s_next is 1 because deterministic\n","                    if s_next in g.rewards:\n","                        rewards[(s, a, s_next)] = g.rewards[s_next]\n","    return transition_probs, rewards"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvHbZzYcQ2he","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597993299820,"user_tz":-420,"elapsed":1167,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def evaluate_deterministic_policy(g, policy):\n","    V = {}\n","    for s in g.all_states():\n","        V[s] = 0\n","    iterations = 0\n","\n","    while True:\n","        biggest_change = 0\n","        for s in g.all_states():\n","            old_v = V[s]\n","            new_v = 0\n","            for a in ACTION_SPACE:\n","                for s_next in g.all_states():\n","                    action_prob = 1 if policy.get(s) == a else 0\n","\n","                    r = rewards.get((s, a, s_next), 0)\n","\n","                    new_v += action_prob * transition_probs.get((s, a, s_next), 0) * (r + gamma * V[s_next])\n","\n","            V[s] = new_v\n","            biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n","\n","        iterations += 1\n","        if biggest_change < delta:\n","            break\n","\n","    return V"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"PIT9v4o4tDgN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597993299822,"user_tz":-420,"elapsed":1005,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":["def get_optimal_policy(g, policy):\n","    while True:\n","        V = evaluate_deterministic_policy(g, policy)\n","\n","        is_policy_converged = True\n","        for s in g.actions.keys():\n","            old_a = policy[s]\n","            new_a = None\n","            best_value = float('-inf')\n","\n","            for a in ACTION_SPACE:\n","                v = 0\n","                for s_next in g.all_states():\n","                    r = rewards.get((s, a, s_next), 0)\n","                    v += transition_probs.get((s, a, s_next), 0) * (r + gamma * V[s_next])\n","\n","                if v > best_value:\n","                    best_value = v\n","                    new_a = a\n","            \n","            policy[s] = new_a\n","\n","            if new_a != old_a:\n","                is_policy_converged = False\n","            \n","        if is_policy_converged:\n","            break\n","    return V, policy"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEMsuj_PrAc4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1597993299823,"user_tz":-420,"elapsed":817,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}},"outputId":"a842f51c-4a09-412a-aaab-f4c577ae78d1"},"source":["# initialize variable\n","g = grid_standard()\n","delta = 1e-3\n","gamma = 0.9\n","\n","# random policy\n","policy = {}\n","for s in g.actions.keys():\n","    policy[s] = np.random.choice(ACTION_SPACE)\n","\n","print(\"initial policy\")\n","print_policy(policy, g)\n","print(\"\")\n","\n","transition_probs, rewards = t_probs_rewards(g)\n","\n","V, policy = get_optimal_policy(g, policy)\n","print(\"optimal policy\")\n","print_policy(policy, g)\n","print(\"V\")\n","print_values(V, g)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["initial policy\n","-------------------------\n"," U | R | U |   |\n","-------------------------\n"," R |   | L |   |\n","-------------------------\n"," U | L | D | U |\n","\n","optimal policy\n","-------------------------\n"," R | R | R |   |\n","-------------------------\n"," U |   | U |   |\n","-------------------------\n"," U | R | U | L |\n","V\n","-------------------------\n"," 0.81| 0.90| 1.00| 0.00|\n","-------------------------\n"," 0.73| 0.00| 0.90| 0.00|\n","-------------------------\n"," 0.66| 0.73| 0.81| 0.73|\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mwvaMqmbsnWr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597993295495,"user_tz":-420,"elapsed":1033,"user":{"displayName":"Hendra Ronaldi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1GApVeWOLfLtzaKM_vycD2e04Atp2_i5j6_Ol=s64","userId":"08624543525853224756"}}},"source":[""],"execution_count":23,"outputs":[]}]}